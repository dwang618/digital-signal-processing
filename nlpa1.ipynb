{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9985be7b-274c-4860-b862-d1b451dcc867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b073ab5870>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import torch\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53af8c-74dd-4d41-955f-877a1b1b11f3",
   "metadata": {},
   "source": [
    "## Question 1: Create a Python list of the first 10 square numbers $(1, 4, 9, ..., 100)$. Convert this list to a NumPy array and reshape it into a $2\\times5$ matrix. Print out the matrix as a 2-dimensional array. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5966d6-eceb-4deb-9dbf-ffe3cd5e51bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "[[  1   4   9  16  25]\n",
      " [ 36  49  64  81 100]]\n"
     ]
    }
   ],
   "source": [
    "list = [x * x for x in range(1, 11)]\n",
    "print(list) \n",
    "\n",
    "arr = np.array(list)\n",
    "arr = np.reshape(arr, (2,5))\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc48b11-3293-49ad-8406-08fbe7b6fddb",
   "metadata": {},
   "source": [
    "## PyTorch Tensors and Operations (9 pts). \n",
    "## Convert the NumPy array from Question 1 into a PyTorch tensor and perform the following operations. The following operations must be done using PyTorch interfaces. \n",
    "(a) Multiply all elements by 2 and print out the sum of all elements. (3 pts) \n",
    "(b) Create a new 5 Ã— 2 tensor by transposing the original tensor. Print out the transposed tensor. (3 pts) \n",
    "(c) Perform matrix multiplication between the original tensor and the transposed tensor. Print out the result. (3 pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d550a2c2-d4bf-4d0e-a7cb-3f35c6332756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(770)\n",
      "tensor([[  1,  36],\n",
      "        [  4,  49],\n",
      "        [  9,  64],\n",
      "        [ 16,  81],\n",
      "        [ 25, 100]], dtype=torch.int32)\n",
      "tensor([[  979,  4604],\n",
      "        [ 4604, 24354]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.from_numpy(arr)\n",
    "tensor_a = tensor * 2\n",
    "print(torch.sum(tensor_a))\n",
    "\n",
    "tensor_b = torch.transpose(tensor, 0,1)\n",
    "print(tensor_b)\n",
    "\n",
    "result = torch.matmul(tensor, tensor_b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fedce79-9182-49f5-9bb3-b56ecf93e6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 20000, \n",
      "Val size: 5000, \n",
      "Test size: 25000\n",
      "Review:  Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n",
      "Sentiment:  Positive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Function that preprocesses the string\n",
    "    \"\"\"\n",
    "    preprocessed_text = text.lower().replace(\"<br />\", \"\")\n",
    "    return preprocessed_text\n",
    "\n",
    "def read_file(file_name, label):\n",
    "    \"\"\"\n",
    "    Function that reads a file\n",
    "    and return the raw text, preprocessed text, and label\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_name, \"r\", encoding='utf-8') as f:\n",
    "            raw_text = f.read()\n",
    "    except UnicodeDecodeError:\n",
    "        # If UTF-8 fails, try with 'latin-1' encoding\n",
    "        with open(file_name, \"r\", encoding='latin-1') as f:\n",
    "            raw_text = f.read()\n",
    "    \n",
    "    preprocessed_text = preprocess_text(raw_text)\n",
    "    return raw_text, preprocessed_text, label\n",
    "\n",
    "def construct_dataset(dataset_dir):\n",
    "    \"\"\"\n",
    "    Function that loads a dataset\n",
    "    \"\"\"\n",
    "    pos_dir = os.path.join(dataset_dir, \"pos\")\n",
    "    neg_dir = os.path.join(dataset_dir, \"neg\")\n",
    "    dir_list = [neg_dir, pos_dir]\n",
    "    raw_contents, contents, labels = [], [], []\n",
    "    all_pos = os.listdir(pos_dir)\n",
    "    all_neg = os.listdir(neg_dir)\n",
    "    data_size = len(all_neg)\n",
    "    for i in range(data_size):\n",
    "        for lbl, dataset in enumerate([all_neg, all_pos]):\n",
    "            cur_path = os.path.join(dir_list[lbl], dataset[i])\n",
    "            if not os.path.isdir(cur_path):\n",
    "                raw_content, content, label = read_file(cur_path, lbl)\n",
    "                contents.append(content)\n",
    "                raw_contents.append(raw_content)\n",
    "                labels.append(label)\n",
    "    return raw_contents, contents, labels\n",
    "\n",
    "# Load training and testing data\n",
    "train_dir = './aclImdb/train'\n",
    "test_dir = './aclImdb/test'\n",
    "sentiments = [\"Negative\", \"Positive\"]\n",
    "\n",
    "train_raw_contents, train_contents, train_labels = construct_dataset(train_dir)\n",
    "test_raw_contents, test_contents, test_labels = construct_dataset(test_dir)\n",
    "\n",
    "# Split train data into training and validation sets\n",
    "train_contents, val_contents, train_labels, val_labels = train_test_split(\n",
    "    train_contents, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(train_contents)}, \"\n",
    "      f\"\\nVal size: {len(val_contents)}, \"\n",
    "      f\"\\nTest size: {len(test_contents)}\")\n",
    "\n",
    "# show the first review and its sentiment label\n",
    "print(\"Review: \", train_raw_contents[0])\n",
    "print(\"Sentiment: \", sentiments[train_labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f993ca7-c1d6-4b6a-b40c-19977640b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "X_train = vectorizer.fit_transform(train_contents).toarray()\n",
    "X_val = vectorizer.transform(val_contents).toarray()\n",
    "X_test = vectorizer.transform(test_contents).toarray()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = torch.tensor(texts, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset = IMDBDataset(X_train, y_train)\n",
    "val_dataset = IMDBDataset(X_val, y_val)\n",
    "test_dataset = IMDBDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb1f7e-e9ab-40d3-92a1-354f4da3b943",
   "metadata": {},
   "source": [
    "## TODO: Implement a simple two-layer neural network using PyTorch's nn.Module for binary classification. The network should have:\n",
    "\n",
    "Then initialize the model where input_dim equals the shape of the data in\n",
    "X_train, the Binary Entropy loss function, and the Adam optimizer with 0.001\n",
    "learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c2b741-ad21-41c4-85dd-b552aa29487b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim  # Add this import statement\n",
    "\n",
    "# TODO: Define a simple 2-layer neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden = nn.Linear(input_dim, 64)\n",
    "        self.relu = nn.ReLU()                        # ReLU activation function\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()                  # Sigmoid activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = SimpleNN(input_dim)\n",
    "criterion = nn.BCELoss()                             # Binary entropy loss function \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Adam optimizer -> 0.001 lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de81ac70-1288-4719-9104-be051869d43e",
   "metadata": {},
   "source": [
    "## Train the neural network for 10 epochs, and print out the training loss and accuracy on the training set at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52dae0f4-e899-459c-acfb-ffa65915e775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.0147, Train Acc: 0.8634, \n",
      "Epoch 2/10, Train Loss: 0.0072, Train Acc: 0.9292, \n",
      "Epoch 3/10, Train Loss: 0.0107, Train Acc: 0.9492, \n",
      "Epoch 4/10, Train Loss: 0.0056, Train Acc: 0.9628, \n",
      "Epoch 5/10, Train Loss: 0.0027, Train Acc: 0.9734, \n",
      "Epoch 6/10, Train Loss: 0.0002, Train Acc: 0.9854, \n",
      "Epoch 7/10, Train Loss: 0.0002, Train Acc: 0.9867, \n",
      "Epoch 8/10, Train Loss: 0.0014, Train Acc: 0.9952, \n",
      "Epoch 9/10, Train Loss: 0.0003, Train Acc: 0.9988, \n",
      "Epoch 10/10, Train Loss: 0.0001, Train Acc: 0.9998, \n"
     ]
    }
   ],
   "source": [
    "## https://pytorch.org/tutorials/beginner/introyt/trainingyt.html#the-training-loop\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # TODO: Complete the training loop, update the training loss and accuracy\n",
    "    for i, (texts, labels) in enumerate(train_loader):\n",
    "        batch_size = texts.size(0)\n",
    "        outputs = model(texts)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * batch_size\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_acc:.4f}, \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f4a59fc-1016-4ddc-a08d-17a0bd0e7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8510\n"
     ]
    }
   ],
   "source": [
    "# TODO: Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, (texts, labels) in enumerate(test_loader):\n",
    "        outputs = model(texts)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        test_correct += (predicted == labels).sum()\n",
    "\n",
    "test_acc = test_correct / len(test_loader.dataset)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
