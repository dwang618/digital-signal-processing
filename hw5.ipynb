{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4df21c",
   "metadata": {},
   "source": [
    "### Homework 5: Time Series Prediction with LTI Systems\n",
    "and Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27df8daa",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "Download the data cho weather.csv, which contains hourly weather at Charlottesville Albemarle Airport (CHO) since 2019\n",
    ". \n",
    "The columns are: \n",
    "\n",
    "tmpf Temperature (F)\n",
    "\n",
    "dwpf Dew Point (F)\n",
    "\n",
    "relh Relative Humidity (%)\n",
    "\n",
    "drct Wind Direction (deg)\n",
    "\n",
    "sped Wind Speed (MPH)\n",
    "\n",
    "mslp Sea Level Pressure (mb)\n",
    "\n",
    "p01i Precipitation (in)\n",
    "\n",
    "Clean the data by filling in missing values with the previous valid value in that column.\n",
    "Missing values are marked with an ‘M’. The letter ‘T’ indicates a trace amount of precipitation.\n",
    "Set these values to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96565aba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pandas.read_csv(\"cho_weather.csv\")\n",
    "data = df.to_numpy()[:, 2:9]\n",
    "print(data)\n",
    "\n",
    "for j in range(data.shape[1]):\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i, j] == \"M\":\n",
    "            data[i, j] = data[i - 1, j]\n",
    "        elif data[i, j] == \"T\":\n",
    "            data[i, j] = 0.0\n",
    "            \n",
    "data = np.float32(data)\n",
    "\n",
    "N = data.shape[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74454a75",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Let’s use LTI systems to predict the weather. Take the exponential moving average (EMA)\n",
    "system that we discussed in class:\n",
    "\n",
    "$y[n] = (1 − g)x[n] + gy[n − 1]$.\n",
    "\n",
    "Given a time series x[n] for n = 0, . . . , L − 1, we can use this as a prediction model for the\n",
    "next timepoint x[n + 1] (that our model has not seen yet) by taking the last output, y[n], as\n",
    "our prediction for x[n + 1]. Implement this exponential averaging system and test it on the\n",
    "provided data of hourly temperatures. Do the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2389cf",
   "metadata": {},
   "source": [
    "(a) Make predictions for $x[n]$ (using $y[n − 1])$ for $n = 1, . . . , L − 1$. \n",
    "Plot these predictions over a plot of the original data. Do this three times, with gain parameters\n",
    "$g = 0.0, 0.25, 0.5, 0.75$. What difference do you see with the four different parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684120dd-a7fe-4df0-a5b5-71a8e3b9bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(x, g):\n",
    "    y = np.zeros_like(x)\n",
    "    y[0] = x[0]\n",
    "    for n in range(1, len(x)):\n",
    "        y[n] = (1 - g) * x[n] + g * y[n-1]\n",
    "    return y\n",
    "\n",
    "g_values = [0.0, 0.25, 0.5, 0.75]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data[:, 0], label='Original Data')\n",
    "\n",
    "for g in g_values:\n",
    "    y_pred = ema(data[:, 0], g)\n",
    "    plt.plot(np.arange(1, len(y_pred)+1), y_pred, label=f'EMA, g={g}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature (F)')\n",
    "plt.title('Temperature Predictions using EMA')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628357e4-6c11-4284-92ec-6f35d8346379",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in g_values:\n",
    "    y_pred = ema(data[:, 0], g)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data[:, 0], label='Original Data')\n",
    "    plt.plot(np.arange(1, len(y_pred)+1), y_pred, label=f'EMA, g={g}')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Temperature (F)')\n",
    "    plt.title(f'Temperature Predictions using EMA, g={g}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be02533",
   "metadata": {},
   "source": [
    "(b) Compute the mean absolute error (MAE) of the four different models (g = 0.0, 0.25, 0.5, 0.75).\n",
    "The MAE is\n",
    "\n",
    "$MAE = \\frac{1}{L-1} \\sum_{i=1}^{L-1} |x[n] - y[n-1]|$\n",
    "\n",
    "Which choice of g gave the best prediction (lowest MAE)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a338a-f98b-4d6e-a5e9-6680f1b66d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae(x, y):\n",
    "    return np.sum(np.abs(x - y)) / (len(x) - 1)\n",
    "\n",
    "g_values = [0.0, 0.25, 0.5, 0.75]\n",
    "maes = []\n",
    "\n",
    "for g in g_values:\n",
    "    y_pred = ema(data[:, 0], g)\n",
    "    mae = compute_mae(data[:, 0], y_pred)\n",
    "    maes.append(mae)\n",
    "    print(f\"MAE for g = {g}: {mae:.4f}\")\n",
    "\n",
    "best_g = g_values[np.argmin(maes)]\n",
    "best_gSTORED_2B = best_g\n",
    "print(f\"The best performing model has g = {best_g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57645b58",
   "metadata": {},
   "source": [
    "(c) Because this is hourly data, our model is really only predicting one hour into the future,\n",
    "which isn’t so hard! Let’s predict further into the future. Repeat your exponential\n",
    "moving average model with a delay of 24 (instead of 1). Now predict x[n + 24] using\n",
    "y[n]. Plot the predictions over the original data again for g = 0.0, 0.25, 0.5, 0.75. Report\n",
    "the MAE for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137373bb-658f-44dd-b7a7-4875b1cc6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ema_24hr(x, g):\n",
    "#    y = np.zeros_like(x)\n",
    "#    y[24:] = (1 - g) * x[:-24] + g * y[:-24]\n",
    "#    return y\n",
    "\n",
    "def ema_24hr(x, g):\n",
    "    y = np.zeros_like(x)\n",
    "    y[0] = x[0]\n",
    "    for n in range(24, len(x)):\n",
    "        y[n] = (1 - g) * x[n-24] + g * y[n-24]\n",
    "    return y\n",
    "\n",
    "\n",
    "g_values = [0.0, 0.25, 0.5, 0.75]\n",
    "maes = []\n",
    "\n",
    "for g in g_values:\n",
    "    y_pred = ema_24hr(data[:, 0], g)\n",
    "    mae = compute_mae(data[24:, 0], y_pred[24:])\n",
    "    maes.append(mae)\n",
    "    print(f\"MAE for g = {g} with 24-hour delay: {mae:.4f}\")\n",
    "\n",
    "best_g = g_values[np.argmin(maes)]\n",
    "best_gSTORED_2C = best_g\n",
    "print(f\"The best performing model has g = {best_g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc0f6fc",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "(d) Now try running your EMA system with a delay of 8 hours to predict 8 hours ahead.\n",
    "You don’t need to plot, just report the MAE for the same four gain values. What do\n",
    "you notice about how this model performs compared to predicting a full 24 hours ahead?\n",
    "Give a conjecture for why you think the performance difference is they way it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4e4ec-4436-4d61-9351-fca1065d6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema_8hr(x, g):\n",
    "    y = np.zeros_like(x)\n",
    "    y[0] = x[0]\n",
    "    for n in range(8, len(x)):\n",
    "        y[n] = (1 - g) * x[n-8] + g * y[n-8]\n",
    "    return y\n",
    "\n",
    "# Compute MAE for each EMA model with 8-hour delay\n",
    "g_values = [0.0, 0.25, 0.5, 0.75]\n",
    "maes = []\n",
    "\n",
    "for g in g_values:\n",
    "    y_pred = ema_8hr(data[:, 0], g)\n",
    "    mae = compute_mae(data[8:, 0], y_pred[8:])\n",
    "    maes.append(mae)\n",
    "    print(f\"MAE for g = {g} with 8-hour delay: {mae:.4f}\")\n",
    "\n",
    "best_g = g_values[np.argmin(maes)]\n",
    "best_gSTORED_2D = best_g\n",
    "print(f\"The best performing model has g = {best_g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08259a5",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## NEURAL NETWORKS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d288a9",
   "metadata": {},
   "source": [
    "At the end of this exercise, you’ll have several trained models: 3 linear and 1 RNN (possibly\n",
    "one more if you do extra credit problem #8). For each model, save it as a *.pt file using\n",
    "the provided code. You will turn in these models with your code. At the end of\n",
    "the assignment report the test accuracy (MAE) for all of the competing models. Write a\n",
    "paragraph about what you learned in terms of which models perform the best, what are the\n",
    "challenges in getting them to work, and what are the pros and cons of each model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce864ce1",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Now let’s train neural networks to predict the weather. Throughout this part, we will reserve\n",
    "the last year of data to use as test data to evaluate the performance of our models. The\n",
    "last year is 365days × 24hrs/day = 8760 time points. First, take your best-performing EMA\n",
    "models above and evaluate their performance (MAE) on the test data. (You may want to\n",
    "write a function that runs a model on the test data and outputs its MAE because you’ll need\n",
    "to repeat this for several models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9e3f8-36f7-4be5-818a-17049f5d43e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best EMA model on the test set\n",
    "def evaluate_model(model, test_data):\n",
    "    if isinstance(model, np.ndarray):\n",
    "        test_predictions = model[-len(test_data):]\n",
    "    else:\n",
    "        test_predictions = model(test_data)\n",
    "    return compute_mae(test_data, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b479ca9-54fb-41c5-8bf4-758ce13326c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best EMA model from part 2b\n",
    "\n",
    "best_g = best_gSTORED_2B  # Assuming you stored the best gain parameter in this variable\n",
    "best_ema_model = ema(train_data, best_g)\n",
    "\n",
    "best_ema_mae = evaluate_model(best_ema_model, test_data)\n",
    "print(f\"Best EMA model with no delay (g={best_g}) MAE on test set: {best_ema_mae:.4f}\")\n",
    "\n",
    "# Compute EMA models with 8-hour and 24-hour delays\n",
    "ema_8hr_model = ema_8hr(train_data, best_gSTORED_2D)\n",
    "ema_24hr_model = ema_24hr(train_data, best_gSTORED_2C)\n",
    "\n",
    "best_g = best_gSTORED_2D\n",
    "\n",
    "# Evaluate 8-hour and 24-hour EMA models on the test set\n",
    "ema_8hr_mae = evaluate_model(ema_8hr_model, test_data[8:])\n",
    "print(f\"EMA 8-hour model (g={best_g}) MAE on test set: {ema_8hr_mae:.4f}\")\n",
    "\n",
    "best_g = best_gSTORED_2C\n",
    "\n",
    "ema_24hr_mae = evaluate_model(ema_24hr_model, test_data[24:])\n",
    "print(f\"EMA 24-hour model (g={best_g}) MAE on test set: {ema_24hr_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0522c56a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Question 4\n",
    " Train a single-layer, linear neural network prediction model (LinearPrediction in the provided code). Use at least one full year of timepoints for training data (make sure your training\n",
    "data is separate from the test data!). Experiment with the window size (how many time points\n",
    "to incorporate in the prediction), the learning rate, and the number of epochs to train. You\n",
    "should be able to choose parameters such that the training runs in a reasonably short amount\n",
    "of time and the final result performs better than EMA on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbdf90a-cd94-4697-a073-e6e396fce746",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearPredictor(nn.Module):\n",
    "    def __init__(self, window_size, y_size = 1):\n",
    "        super(LinearPredictor, self).__init__()\n",
    "        self.y_size = y_size\n",
    "        self.window_size = window_size\n",
    "        self.linear = nn.Linear(window_size, 1)\n",
    "\n",
    "    ## Here h is a dummy hidden variable, just to make this call the same as an RNN\n",
    "    def forward(self, x, h):\n",
    "        y = self.linear(x.reshape(1, self.window_size))\n",
    "        return y.reshape(self.y_size), h\n",
    "\n",
    "def train(targets, x, model, window_size, optimizer, num_epochs, criterion, h_size = 1):\n",
    "    N = x.shape[0]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for i in range(window_size, N):\n",
    "            model.zero_grad()\n",
    "            \n",
    "            h = torch.zeros(1, h_size)\n",
    "            ## this?\n",
    "            ## y, h = model(x[(i - window_size - offset):(i - offset)], h)\n",
    "            y, h = model(x[(i - window_size):i], h)\n",
    "\n",
    "            loss = criterion(y, targets[i])\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.detach()\n",
    "\n",
    "        # convert to mean loss\n",
    "        total_loss = total_loss / (N - window_size)\n",
    "            \n",
    "        print(epoch, \": Training Loss = \", total_loss.item())\n",
    "\n",
    "# Pull out the temperature time series\n",
    "temps = data[:, 0]\n",
    "test_data = data[-8760:, 0]\n",
    "train_data = data[:-8760, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbd67c-d263-4fe7-a475-4f717905ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 hour prediction - 11.8321 is the MAE to beat\n",
    "\n",
    "### SET YOUR PARAMETERS HERE! ####\n",
    "###\n",
    "learning_rate = 0.001\n",
    "num_epochs = 3\n",
    "window_size = 4\n",
    "x_size = 3\n",
    "h_size = 5\n",
    "y_size = 3\n",
    "# modified above\n",
    "\n",
    "# model = RNN(x_size, h_size, y_size)\n",
    "### OR ###\n",
    "model = LinearPredictor(window_size)\n",
    "\n",
    "# Set up your loss function (MAE)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Set up a gradient descent optimizer\n",
    "# You might also try \"SGD\" instead of \"Adam\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Define inputs and targets\n",
    "# You should define \"start\" and \"end\" of the training data\n",
    "# \"offset\" is how far in the future you want to predict (prediction will be (offset + 1) timepoints in the future)\n",
    "start = 0\n",
    "end = 8760\n",
    "offset = 0\n",
    "#modified start, end, offset\n",
    "L = end - start\n",
    "#x = torch.Tensor(temps[start:end]).reshape(L, 1)\n",
    "#targets = torch.Tensor(temps[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "x = torch.Tensor(train_data[start:end]).reshape(L, 1)\n",
    "targets = torch.Tensor(train_data[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "\n",
    "out_y = train(targets, x, model, window_size, optimizer, num_epochs, criterion, h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadfb3c6-e93e-4b84-9c54-7f6fd47a38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how you save a trained model.\n",
    "torch.save(model.state_dict(), \"LNR_1HR.pt\")\n",
    "\n",
    "# And here is how you would load such a saved model\n",
    "# Make sure you can reload the model and that it gives the same test results that you expect!\n",
    "# You have to call the same model creation code \"LinearPredictor\" or \"RNN\" to create the model first\n",
    "model = LinearPredictor(window_size)\n",
    "model.load_state_dict(torch.load(\"LNR_1 HR.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611bc178",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Question 5\n",
    "Train two more LinearPrediction models, now with the targets being 8 hours (offset =\n",
    "7) and 24 hours (offset = 23) in the future. You might start with the same parameters you\n",
    "used in the previous problem and adjust them only if they don’t work well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262b2ee-aff7-46fe-a296-9b7f93fd5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 hour prediction - 9.1836 is the MAE to beat\n",
    "\n",
    "### SET YOUR PARAMETERS HERE! ####\n",
    "###\n",
    "learning_rate = 0.008\n",
    "num_epochs = 5\n",
    "window_size = 4\n",
    "x_size = 4\n",
    "h_size = 5\n",
    "y_size = 4\n",
    "# modified above\n",
    "\n",
    "# model = RNN(x_size, h_size, y_size)\n",
    "### OR ###\n",
    "model = LinearPredictor(window_size)\n",
    "\n",
    "# Set up your loss function (MAE)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Set up a gradient descent optimizer\n",
    "# You might also try \"SGD\" instead of \"Adam\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Define inputs and targets\n",
    "# You should define \"start\" and \"end\" of the training data\n",
    "# \"offset\" is how far in the future you want to predict (prediction will be (offset + 1) timepoints in the future)\n",
    "start = 0\n",
    "end = 8760\n",
    "offset = 7\n",
    "#modified start, end, offset\n",
    "L = end - start\n",
    "#x = torch.Tensor(temps[start:end]).reshape(L, 1)\n",
    "#targets = torch.Tensor(temps[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "x = torch.Tensor(train_data[start:end]).reshape(L, 1)\n",
    "targets = torch.Tensor(train_data[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "\n",
    "out_y = train(targets, x, model, window_size, optimizer, num_epochs, criterion, h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e911106-f404-407d-915d-feb5337cd54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how you save a trained model.\n",
    "torch.save(model.state_dict(), \"LNR_8HR.pt\")\n",
    "\n",
    "# And here is how you would load such a saved model\n",
    "# Make sure you can reload the model and that it gives the same test results that you expect!\n",
    "# You have to call the same model creation code \"LinearPredictor\" or \"RNN\" to create the model first\n",
    "model = LinearPredictor(window_size)\n",
    "model.load_state_dict(torch.load(\"LNR_8HR.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e849e32d-7927-4897-a607-c54a71546ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 hour prediction - 11.0766 is the MAE to beat\n",
    "\n",
    "### SET YOUR PARAMETERS HERE! ####\n",
    "###\n",
    "learning_rate = 0.008\n",
    "num_epochs = 5\n",
    "window_size = 4\n",
    "x_size = 4\n",
    "h_size = 5\n",
    "y_size = 4\n",
    "# modified above\n",
    "\n",
    "# model = RNN(x_size, h_size, y_size)\n",
    "### OR ###\n",
    "model = LinearPredictor(window_size)\n",
    "\n",
    "# Set up your loss function (MAE)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Set up a gradient descent optimizer\n",
    "# You might also try \"SGD\" instead of \"Adam\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Define inputs and targets\n",
    "# You should define \"start\" and \"end\" of the training data\n",
    "# \"offset\" is how far in the future you want to predict (prediction will be (offset + 1) timepoints in the future)\n",
    "start = 0\n",
    "end = 8760\n",
    "offset = 23\n",
    "#modified start, end, offset\n",
    "L = end - start\n",
    "#x = torch.Tensor(temps[start:end]).reshape(L, 1)\n",
    "#targets = torch.Tensor(temps[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "x = torch.Tensor(train_data[start:end]).reshape(L, 1)\n",
    "targets = torch.Tensor(train_data[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "\n",
    "out_y = train(targets, x, model, window_size, optimizer, num_epochs, criterion, h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d9a73-2637-43b6-a36f-b58d69db6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how you save a trained model.\n",
    "torch.save(model.state_dict(), \"LNR_24HR.pt\")\n",
    "\n",
    "# And here is how you would load such a saved model\n",
    "# Make sure you can reload the model and that it gives the same test results that you expect!\n",
    "# You have to call the same model creation code \"LinearPredictor\" or \"RNN\" to create the model first\n",
    "model = LinearPredictor(window_size)\n",
    "model.load_state_dict(torch.load(\"LNR_24HR.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f7f6c",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Now train an recurrent neural network (RNN) model to predict the temperature one hour\n",
    "into the future. Now, you will need to experiment with the hidden variable size, the learning\n",
    "rate, the window size, and the number of epochs. Start small with the hidden variable size\n",
    "and window size, and increase them if the computation time is not too long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b280be-aa6a-479d-8590-b1e54a44b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 hour prediction - 11.0766 is the MAE to beat\n",
    "\n",
    "### SET YOUR PARAMETERS HERE! ####\n",
    "###\n",
    "learning_rate = 0.008\n",
    "num_epochs = 3\n",
    "window_size = 4\n",
    "x_size = 1\n",
    "h_size = 3\n",
    "y_size = 1\n",
    "# modified above\n",
    "\n",
    "model = RNN(x_size, h_size, y_size)\n",
    "### OR ###\n",
    "# model = LinearPredictor(window_size)\n",
    "\n",
    "# Set up your loss function (MAE)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Set up a gradient descent optimizer\n",
    "# You might also try \"SGD\" instead of \"Adam\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Define inputs and targets\n",
    "# You should define \"start\" and \"end\" of the training data\n",
    "# \"offset\" is how far in the future you want to predict (prediction will be (offset + 1) timepoints in the future)\n",
    "start = 0\n",
    "end = 8760\n",
    "offset = 0 # offset is 0, so predicts 1 hr into future\n",
    "#modified start, end, offset\n",
    "L = end - start\n",
    "#x = torch.Tensor(temps[start:end]).reshape(L, 1)\n",
    "#targets = torch.Tensor(temps[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "x = torch.Tensor(train_data[start:end]).reshape(L, 1)\n",
    "targets = torch.Tensor(train_data[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "\n",
    "out_y = train(targets, x, model, window_size, optimizer, num_epochs, criterion, h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67708d2a-3b1b-4945-bfd5-302f0f6a81a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how you save a trained model.\n",
    "torch.save(model.state_dict(), \"RNN_1HR.pt\")\n",
    "\n",
    "# And here is how you would load such a saved model\n",
    "# Make sure you can reload the model and that it gives the same test results that you expect!\n",
    "# You have to call the same model creation code \"LinearPredictor\" or \"RNN\" to create the model first\n",
    "model = LinearPredictor(window_size)\n",
    "model.load_state_dict(torch.load(\"RNN_1HR.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00395da5",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Write a function to use your RNN to predict farther into the future by recursively feeding the\n",
    "outputs yn as the next inputs xn+1. Use this to predict 8 hours into the future and compare\n",
    "the performance with the EMA and linear neural network models. Repeat this for 24 hours\n",
    "into the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63145e3-c111-45ca-8297-981b536e2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 hour prediction - 9.1836 is the MAE to beat\n",
    "\n",
    "### SET YOUR PARAMETERS HERE! ####\n",
    "###\n",
    "learning_rate = 0.008\n",
    "num_epochs = 3\n",
    "window_size = 4\n",
    "x_size = 1\n",
    "h_size = 3\n",
    "y_size = 1\n",
    "# modified above\n",
    "\n",
    "model = RNN(x_size, h_size, y_size)\n",
    "### OR ###\n",
    "# model = LinearPredictor(window_size)\n",
    "\n",
    "# Set up your loss function (MAE)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Set up a gradient descent optimizer\n",
    "# You might also try \"SGD\" instead of \"Adam\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Define inputs and targets\n",
    "# You should define \"start\" and \"end\" of the training data\n",
    "# \"offset\" is how far in the future you want to predict (prediction will be (offset + 1) timepoints in the future)\n",
    "start = 0\n",
    "end = 8760\n",
    "offset = 7 # offset is 0, so predicts 1 hr into future\n",
    "#modified start, end, offset\n",
    "L = end - start\n",
    "#x = torch.Tensor(temps[start:end]).reshape(L, 1)\n",
    "#targets = torch.Tensor(temps[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "x = torch.Tensor(train_data[start:end]).reshape(L, 1)\n",
    "targets = torch.Tensor(train_data[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "\n",
    "out_y = train(targets, x, model, window_size, optimizer, num_epochs, criterion, h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad03e0-7a0a-4edf-b62c-c120156a53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how you save a trained model.\n",
    "torch.save(model.state_dict(), \"RNN_8HR.pt\")\n",
    "\n",
    "# And here is how you would load such a saved model\n",
    "# Make sure you can reload the model and that it gives the same test results that you expect!\n",
    "# You have to call the same model creation code \"LinearPredictor\" or \"RNN\" to create the model first\n",
    "model = LinearPredictor(window_size)\n",
    "model.load_state_dict(torch.load(\"RNN_8HR.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c547a-a1ef-44ec-9dc5-f80362cb339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 hour prediction - 11.0766 is the MAE to beat\n",
    "\n",
    "### SET YOUR PARAMETERS HERE! ####\n",
    "###\n",
    "learning_rate = 0.008\n",
    "num_epochs = 3\n",
    "window_size = 4\n",
    "x_size = 1\n",
    "h_size = 3\n",
    "y_size = 1\n",
    "# modified above\n",
    "\n",
    "model = RNN(x_size, h_size, y_size)\n",
    "\n",
    "# Set up your loss function (MAE)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Set up a gradient descent optimizer\n",
    "# You might also try \"SGD\" instead of \"Adam\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Define inputs and targets\n",
    "# You should define \"start\" and \"end\" of the training data\n",
    "# \"offset\" is how far in the future you want to predict (prediction will be (offset + 1) timepoints in the future)\n",
    "start = 0\n",
    "end = 8760\n",
    "offset = 23 # offset is 0, so predicts 1 hr into future\n",
    "#modified start, end, offset\n",
    "L = end - start\n",
    "#x = torch.Tensor(temps[start:end]).reshape(L, 1)\n",
    "#targets = torch.Tensor(temps[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "x = torch.Tensor(train_data[start:end]).reshape(L, 1)\n",
    "targets = torch.Tensor(train_data[(start + offset):(end + offset)]).reshape(L, 1)\n",
    "\n",
    "out_y = train(targets, x, model, window_size, optimizer, num_epochs, criterion, h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01202796-a6e3-4e67-8cc9-9e0be9a62930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how you save a trained model.\n",
    "torch.save(model.state_dict(), \"RNN_24HR.pt\")\n",
    "\n",
    "# And here is how you would load such a saved model\n",
    "# Make sure you can reload the model and that it gives the same test results that you expect!\n",
    "# You have to call the same model creation code \"LinearPredictor\" or \"RNN\" to create the model first\n",
    "model = LinearPredictor(window_size)\n",
    "model.load_state_dict(torch.load(\"RNN_24HR.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20342f76",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "Train an improved neural network such that you can beat the performance of EMA and the\n",
    "linear neural network in predicting 24 hours into the future. You might consider training the\n",
    "RNN to directly predict targets 24 hours ahead, modifying the RNN to be an LSTM, using\n",
    "the other weather variables (wind, pressure, etc.), or other ideas. This is open ended!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110441a-431c-42d6-ba47-1f5ecdf04be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.008\n",
    "num_epochs = 3\n",
    "window_size = 4\n",
    "x_size = 1\n",
    "h_size = 3\n",
    "y_size = 1\n",
    "\n",
    "model = nn.LSTM(x_size, h_size, batch_first=True)\n",
    "\n",
    "# Set up your loss function (MAE)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Set up a gradient descent optimizer\n",
    "# You might also try \"SGD\" instead of \"Adam\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define inputs and targets\n",
    "# You should define \"start\" and \"end\" of the training data\n",
    "# \"offset\" is how far in the future you want to predict (prediction will be (offset + 1) timepoints in the future)\n",
    "start = 0\n",
    "end = 8760\n",
    "offset = 23 # offset is 0, so predicts 1 hr into future\n",
    "L = end - start\n",
    "x = torch.Tensor(train_data[start:end]).reshape(L, 1, 1)\n",
    "targets = torch.Tensor(train_data[(start + offset):(end + offset)]).reshape(L, 1, 1)\n",
    "\n",
    "# Train the LSTM model\n",
    "out_y = train(targets, x, model, window_size, optimizer, num_epochs, criterion, h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc185f3c-ddb0-4a0c-8437-3b4e5f8d9ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how you save a trained model.\n",
    "torch.save(model.state_dict(), \"LSTM_24HR.pt\")\n",
    "\n",
    "# And here is how you would load such a saved model\n",
    "# Make sure you can reload the model and that it gives the same test results that you expect!\n",
    "# You have to call the same model creation code \"LinearPredictor\" or \"RNN\" to create the model first\n",
    "model = LinearPredictor(window_size)\n",
    "model.load_state_dict(torch.load(\"LSTM_24HR.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
